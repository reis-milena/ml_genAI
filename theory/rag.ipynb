{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval-Augmented Generation - RAG\n",
    "\n",
    "\"RAG (Retrieval-Augmented Generation) is an AI framework that combines the strengths of traditional information retrieval systems (such as databases) with the capabilities of generative large language models (LLMs).  By combining this extra knowledge with its own language skills, the AI can write text that is more accurate, up-to-date, and relevant to your specific needs.\"\n",
    "\n",
    "- You query some external database for the answers instead of relying on the LLM. Then, work those ansers into the prompt for the LLM to work with. Or use tools and functions to incorporate the search into the LLM in a slightly more principled way.\n",
    "\n",
    "**Retrieval and Pre-processing**: \"RAGs leverage powerful search algorithms to query external data, such as web pages, knowledge bases, and databases. Once retrieved, the relevant information undergoes pre-processing, including tokenization, stemming, and removal of stop words.\"\n",
    "\n",
    "\n",
    "**Generation**: \"The pre-processed retrieved information is then seamlessly incorporated into the pre-trained LLM. This integration enhances the LLM's context, providing it with a more comprehensive understanding of the topic. This augmented context enables the LLM to generate more precise, informative, and engaging responses.\"\n",
    "\n",
    "![](https://pvml.com/wp-content/uploads/2024/04/rag.png)\n",
    "\n",
    "![](https://www.researchgate.net/publication/376182986/figure/fig1/AS:11431281209189268@1701699959336/Retrieval-augmented-generation.ppm)\n",
    "\n",
    "## Pros VS Cons\n",
    "\n",
    "Pros:\n",
    "\n",
    "- Faster and cheaper way to incorporate new or proprietary information into \"GenAI\" vs fine-tuning.\n",
    "\n",
    "- Updating info is just a matter of updating a database.\n",
    "\n",
    "- Can prevent 'hallucinations' when you ask the model about something it wasn't trained on.\n",
    "\n",
    "- If your boss wants 'AI search' this is an easy way to deliver it.\n",
    "\n",
    "- Technically you aren't 'training' a model with this data\n",
    "\n",
    "Cons:\n",
    "\n",
    "- You have made the world's most overcomplicated seach engine\n",
    "\n",
    "- Very sensitive to the prompt templates you use to incorporate your data\n",
    "\n",
    "- Non-deterministic\n",
    "\n",
    "- It can still hallucinate\n",
    "\n",
    "- Very sensitive to the relevancy of the information you retrieve\n",
    "\n",
    "## Vector database\n",
    "\n",
    "- An embedding is just a big vector associated with your data.\n",
    "\n",
    "- Embeddings are computed such that items that are similar to each other are close to each other in that space.\n",
    "\n",
    "A vector database stores your data alongside their computed embedding vectors."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
